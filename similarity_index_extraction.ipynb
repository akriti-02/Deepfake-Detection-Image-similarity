{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity Index"
      ],
      "metadata": {
        "id": "pp6IgTLiUwrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for SSIM and MSE and MS-SSIM\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from skimage import metrics\n",
        "from skimage import measure\n",
        "def mse(imageA, imageB):\n",
        "    # the 'Mean Squared Error' between the two images is the\n",
        "    # sum of the squared difference between the two images;\n",
        "    # NOTE: the two images must have the same dimension\n",
        "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "    err /= float(imageA.shape[0] * imageA.shape[1])# return the MSE, the lower the error, the more \"similar\"\n",
        "    # the two images are\n",
        "    return err\n",
        "def compare_images(imageA, imageB):\n",
        "    # compute the mean squared error and structural similarity\n",
        "    # index for the images\n",
        "    s = ssim(imageA, imageB,multichannel=True)\n",
        "    return s\n",
        "def multissim(imageA, imageB):\n",
        "    ms_ssim = compare_ssim(imageA, imageB,multichannel=True)\n",
        "    return ms_ssim\n",
        "\n",
        "def euclidian_dis(imageA, imageB):\n",
        "    # Ensure both images have the same shape (e.g., resize them)\n",
        "    imageA = np.array(imageA)\n",
        "    imageB = np.array(imageB)\n",
        "    if imageA.shape != imageB.shape:\n",
        "        common_shape = (min(imageA.shape[0], imageB.shape[0]), min(imageA.shape[1], imageB.shape[1]))\n",
        "        imageA = imageA[:common_shape[0], :common_shape[1]]\n",
        "        imageB = imageB[:common_shape[0], :common_shape[1]]\n",
        "\n",
        "    # Calculate the Euclidean distance between the two images\n",
        "    euclidean_distance = np.linalg.norm(imageA - imageB)\n",
        "    return euclidean_distance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3IAoKF7pUTry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def compare_images_in_directory(directory_path, target_image_path):\n",
        "    target_image = cv.imread(target_image_path)\n",
        "    if target_image is None:\n",
        "        print(f\"Failed to read the target image: {target_image_path}\")\n",
        "        return\n",
        "\n",
        "    data = {\n",
        "        'Image Name': [],\n",
        "        'SSIM Score': [],\n",
        "        'MSE Error': [],\n",
        "        'MS-SSIM Score': [],\n",
        "        'Euclidean Distance': []\n",
        "    }\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            image = cv.imread(image_path)\n",
        "\n",
        "            if target_image.shape != image.shape:\n",
        "                a, b, c = target_image.shape\n",
        "                image = cv.resize(image, dsize=(b, a), interpolation=cv.INTER_LINEAR)\n",
        "\n",
        "                if image is not None:\n",
        "                    ssim_score = compare_images(target_image, image)\n",
        "                    mse_error=mse(target_image, image)\n",
        "                    ms_ssim_score=multissim(target_image, image)\n",
        "                    eucl_score=euclidian_dis(target_image, image)\n",
        "\n",
        "                    data['Image Name'].append(filename)\n",
        "                    data['SSIM Score'].append(ssim_score)\n",
        "                    data['MSE Error'].append(mse_error)\n",
        "                    data['MS-SSIM Score'].append(ms_ssim_score)\n",
        "                    data['Euclidean Distance'].append(eucl_score)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('/content/image_comparison_results_2.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iKR0Stn7UTn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV FILE 1\n",
        "#Example usage:\n",
        "directory_path = 'image directory in which we extracted the features'\n",
        "target_image_path = 'target image of the person whose picture was used for deepfake ( try to use original image which was used to swapp the video)'\n",
        "compare_images_in_directory(directory_path, target_image_path)"
      ],
      "metadata": {
        "id": "apAhGwTEUTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orb(img1,img2):\n"
      ],
      "metadata": {
        "id": "4FF95VZfUwFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV FILE 2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import ContrastiveLoss\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "\n",
        "import pandas as pd\n",
        "# Function to create a simple Convolutional Neural Network (CNN)\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    return model\n",
        "\n",
        "# Load images from a directory\n",
        "def load_images_from_directory(directory):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (64, 64))  # Resize images to a consistent size\n",
        "            images.append(img)\n",
        "            filenames.append(filename)\n",
        "    return np.array(images), filenames\n",
        "\n",
        "# Define the input shape based on your image size and channels\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "# Specify the directory containing your images\n",
        "image_directory = \"/content/drive/MyDrive/celeb_face_ext\"\n",
        "\n",
        "# Load images and filenames from the directory\n",
        "image_data, filenames = load_images_from_directory(image_directory)\n",
        "\n",
        "# Add batch dimension and normalize the images\n",
        "image_data = image_data / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "# Create and compile the CNN model\n",
        "model = create_cnn_model(input_shape)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Extract features from the images using the CNN\n",
        "features = model.predict(image_data)\n",
        "\n",
        "# Load the target image\n",
        "target_image_path = \"/content/deepfakend data.jpg\"\n",
        "target_image = cv2.imread(target_image_path)\n",
        "target_image = cv2.resize(target_image, (64, 64))  # Resize to match other images\n",
        "target_image = target_image / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "target_image = np.expand_dims(target_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Extract features from the target image using the CNN\n",
        "target_features = model.predict(target_image)\n",
        "\n",
        "# Calculate Euclidean distances between the target image and all other images\n",
        "distances = []\n",
        "\n",
        "for i in range(features.shape[0]):\n",
        "    distance = euclidean(target_features.flatten(), features[i].flatten())\n",
        "    distances.append(distance)\n",
        "\n",
        "# Create a DataFrame with filenames and distances\n",
        "result_df = pd.DataFrame({'Filename': filenames, 'Euclidean Distance': distances})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "result_df.to_csv('/content/drive/MyDrive/conv_euc_results.csv', index=False)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "VNl5F4nZVFSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  TO JOIN THE TWO DIFFERNT CSV FILES WE GET\n",
        "#import pandas as pd\n",
        "df1 = pd.read_csv('/content/image_comparison_results(4).csv')\n",
        "df2 = pd.read_csv('/content/image_comparison_results_2.csv')\n",
        "\n",
        "# Concatenate along rows (axis=0)\n",
        "result = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
        "# Assuming 'result' is the concatenated DataFrame\n",
        "result.to_csv('/content/concatenated_celeb_data.csv', index=False)\n",
        "\n",
        "# Print the concatenated result\n",
        "print(result)"
      ],
      "metadata": {
        "id": "vsgnXR7kVFNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-p5S15UGVFKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMKdwzklVFID"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}