{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Deepfake Video\n"
      ],
      "metadata": {
        "id": "Ai1lrHTfQb4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86x2RRe3P3Us"
      },
      "outputs": [],
      "source": [
        "# use Roop Repository\n",
        "\n",
        "!git clone https://github.com/s0md3v/roop.git\n",
        "%cd roop\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx -O inswapper_128.onnx\n",
        "!mkdir models\n",
        "!mv inswapper_128.onnx ./models"
      ],
      "metadata": {
        "id": "AVYYfZ97Qz6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall onnxruntime onnxruntime-gpu -y\n",
        "!pip install torch torchvision torchaudio --force-reinstall --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "TZmpMrJ0Q_6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --target \"targeted video destination\"  --source \"source image destination\" -o \"output image destination\" --execution-provider cuda --frame-processor face_swapper face_enhancer"
      ],
      "metadata": {
        "id": "Baf41fOwQ_3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Deepfake Video\n"
      ],
      "metadata": {
        "id": "rN4tTWiQRZZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline\n",
        "import cv2 as cv\n",
        "import glob2\n",
        "import fnmatch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aAb-Ubw4SY8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition"
      ],
      "metadata": {
        "id": "QZUbuZwNRAH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "fig, ax = plt.subplots(1,1, figsize=(15, 15))\n",
        "video_file = 'file location'\n",
        "cap = cv.VideoCapture(video_file)\n",
        "success, image = cap.read()\n",
        "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "cap.release()\n",
        "ax.imshow(image)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.yaxis.set_visible(False)\n",
        "ax.title.set_text(f\"FRAME 0: {video_file.split('/')[-1]}\")\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "VutCpAC9RAEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
        "\n",
        "for face_location in face_locations:\n",
        "\n",
        "    # Print the location of each face in this image\n",
        "    top, right, bottom, left = face_location\n",
        "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "\n",
        "    # You can access the actual face itself like this:\n",
        "    face_image = image[top:bottom, left:right]\n",
        "    fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "    plt.grid(False)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "    ax.imshow(face_image)\n",
        "    plt.imsave(\"output image location\", face_image)"
      ],
      "metadata": {
        "id": "GXdellozRACO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "image = cv.imread(\"image location\", cv.IMREAD_COLOR)\n",
        "\n",
        "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "cap.release()\n",
        "face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
        "\n",
        "for face_location in face_locations:\n",
        "\n",
        "    # Print the location of each face in this image\n",
        "    top, right, bottom, left = face_location\n",
        "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "\n",
        "    # You can access the actual face itself like this:\n",
        "    face_image = image[top:bottom, left:right]\n",
        "    fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "    plt.grid(False)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "    ax.imshow(face_image)\n",
        "    plt.imsave(\"face detected image saving location\", face_image)"
      ],
      "metadata": {
        "id": "L5iCe7cnQ__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frames calculation\n",
        "cap = cv.VideoCapture(video_file)\n",
        "\n",
        "frames = []\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret==True:\n",
        "        frames.append(frame)\n",
        "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "\n",
        "print('The number of frames saved: ', len(frames))"
      ],
      "metadata": {
        "id": "DRXIb79UQ_1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes = np.array(axes)\n",
        "axes = axes.reshape(-1)\n",
        "ax_ix = 0\n",
        "padding = 40\n",
        "for i in [0, 15,30,45,60,75,90]:\n",
        "    frame = frames[i]\n",
        "    #fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "    face_locations = face_recognition.face_locations(frame)\n",
        "    if len(face_locations) == 0:\n",
        "        print(f'Could not find face in frame {i}')\n",
        "        continue\n",
        "    top, right, bottom, left = face_locations[0]\n",
        "    frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
        "    image = cv.cvtColor(frame_face, cv.COLOR_BGR2RGB)\n",
        "    axes[ax_ix].imshow(image)\n",
        "    axes[ax_ix].xaxis.set_visible(False)\n",
        "    axes[ax_ix].yaxis.set_visible(False)\n",
        "    axes[ax_ix].set_title(f'Frame {i}')\n",
        "    ax_ix += 1\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DhPauApRQ_yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**deepfaked video frame and face detection**"
      ],
      "metadata": {
        "id": "YE8cHVJ_SKZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(15, 15))\n",
        "video_file = '/content/videoformating.mp4'\n",
        "cap = cv.VideoCapture(video_file)\n",
        "success, image = cap.read()\n",
        "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "cap.release()\n",
        "ax.imshow(image)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.yaxis.set_visible(False)\n",
        "ax.title.set_text(f\"FRAME 0: {video_file.split('/')[-1]}\")\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "mD_O7ng4Q_vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
        "\n",
        "for face_location in face_locations:\n",
        "\n",
        "    # Print the location of each face in this image\n",
        "    top, right, bottom, left = face_location\n",
        "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "\n",
        "    # You can access the actual face itself like this:\n",
        "    face_image = image[top:bottom, left:right]\n",
        "    fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "    plt.grid(False)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "    ax.imshow(face_image)\n",
        "    plt.imsave(\"/content/real.png\", face_image)"
      ],
      "metadata": {
        "id": "v602ojweSPw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAFjK0vNSPtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDqh5HPvSSF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noUBns7PSSC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mINnJevWSR_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogyfbGYYSR7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}